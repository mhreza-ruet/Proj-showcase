## Vision Transformer for Image Classification

This project was developed as part of a computer vision course, focusing on the **implementation** of a Vision Transformer (ViT) model for image classification. The goal was to understand the architecture and workflow of ViTs rather than achieving state-of-the-art accuracy.

### Project Highlights
- Implemented a **Vision Transformer (ViT)** from scratch in PyTorch.  
- Trained and evaluated the model on the **CIFAR-10 dataset**.  
- Emphasis placed on understanding **self-attention mechanisms**, patch embeddings, and transformer blocks in the context of computer vision.  
- Since this was a course project, the primary focus was on the **implementation details** rather than extensive hyperparameter tuning or achieving benchmark performance.  

### Skills Demonstrated
- Vision Transformer (ViT) architecture  
- Image classification using PyTorch  
- Attention mechanisms in deep learning  
- Practical experience with CIFAR-10 dataset  
- Course-driven research and experimentation 
